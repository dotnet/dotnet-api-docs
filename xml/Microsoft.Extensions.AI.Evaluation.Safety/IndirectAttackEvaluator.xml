<Type Name="IndirectAttackEvaluator" FullName="Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator">
  <TypeSignature Language="C#" Value="public sealed class IndirectAttackEvaluator : Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi sealed beforefieldinit IndirectAttackEvaluator extends Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />
  <TypeSignature Language="DocId" Value="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" />
  <TypeSignature Language="VB.NET" Value="Public NotInheritable Class IndirectAttackEvaluator&#xA;Inherits ContentSafetyEvaluator" />
  <TypeSignature Language="F#" Value="type IndirectAttackEvaluator = class&#xA;    inherit ContentSafetyEvaluator" />
  <TypeSignature Language="C++ CLI" Value="public ref class IndirectAttackEvaluator sealed : Microsoft::Extensions::AI::Evaluation::Safety::ContentSafetyEvaluator" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.Extensions.AI.Evaluation.Safety</AssemblyName>
    <AssemblyVersion>9.4.0.0</AssemblyVersion>
    <AssemblyVersion>9.5.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator</BaseTypeName>
  </Base>
  <Interfaces />
  <Attributes>
    <Attribute FrameworkAlternate="net-10.0-pp;net-8.0-pp;net-9.0-pp">
      <AttributeName Language="C#">[System.Runtime.CompilerServices.Nullable(0)]</AttributeName>
      <AttributeName Language="F#">[&lt;System.Runtime.CompilerServices.Nullable(0)&gt;]</AttributeName>
    </Attribute>
  </Attributes>
  <Docs>
    <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform
            evaluations.
            </param>
    <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Foundry Evaluation service to evaluate responses produced by
            an AI model for the presence of indirect attacks such as manipulated content, intrusion and information gathering.
            </summary>
    <remarks>
      <para>
            Indirect attacks, also known as cross-domain prompt injected attacks (XPIA), are when jailbreak attacks are
            injected into the context of a document or source that may result in an altered, unexpected behavior. Indirect
            attacks evaluations are broken down into three subcategories:
            </para>
      <para>
            Manipulated Content: This category involves commands that aim to alter or fabricate information, often to mislead
            or deceive.It includes actions like spreading false information, altering language or formatting, and hiding or
            emphasizing specific details.The goal is often to manipulate perceptions or behaviors by controlling the flow and
            presentation of information.
            </para>
      <para>
            Intrusion: This category encompasses commands that attempt to breach systems, gain unauthorized access, or elevate
            privileges illicitly. It includes creating backdoors, exploiting vulnerabilities, and traditional jailbreaks to
            bypass security measures.The intent is often to gain control or access sensitive data without detection.
            </para>
      <para>
            Information Gathering: This category pertains to accessing, deleting, or modifying data without authorization,
            often for malicious purposes. It includes exfiltrating sensitive data, tampering with system records, and removing
            or altering existing information. The focus is on acquiring or manipulating data to exploit or compromise systems
            and individuals.
            </para>
      <para>
        <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" /> returns a <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> with a value of <see langword="true" />
            indicating the presence of an indirect attack in the response, and a value of <see langword="false" /> indicating
            the absence of an indirect attack.
            </para>
      <para>
            Note that <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" /> does not support evaluation of multimodal content present in the
            evaluated responses. Images and other multimodal content present in the evaluated responses will be ignored.
            </para>
    </remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public IndirectAttackEvaluator ();" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor() cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.#ctor" />
      <MemberSignature Language="VB.NET" Value="Public Sub New ()" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; IndirectAttackEvaluator();" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Extensions.AI.Evaluation.Safety</AssemblyName>
        <AssemblyVersion>9.5.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters />
      <Docs>
        <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Foundry Evaluation service to evaluate responses produced by
            an AI model for the presence of indirect attacks such as manipulated content, intrusion and information gathering.
            </summary>
        <remarks>
          <para>
            Indirect attacks, also known as cross-domain prompt injected attacks (XPIA), are when jailbreak attacks are
            injected into the context of a document or source that may result in an altered, unexpected behavior. Indirect
            attacks evaluations are broken down into three subcategories:
            </para>
          <para>
            Manipulated Content: This category involves commands that aim to alter or fabricate information, often to mislead
            or deceive.It includes actions like spreading false information, altering language or formatting, and hiding or
            emphasizing specific details.The goal is often to manipulate perceptions or behaviors by controlling the flow and
            presentation of information.
            </para>
          <para>
            Intrusion: This category encompasses commands that attempt to breach systems, gain unauthorized access, or elevate
            privileges illicitly. It includes creating backdoors, exploiting vulnerabilities, and traditional jailbreaks to
            bypass security measures.The intent is often to gain control or access sensitive data without detection.
            </para>
          <para>
            Information Gathering: This category pertains to accessing, deleting, or modifying data without authorization,
            often for malicious purposes. It includes exfiltrating sensitive data, tampering with system records, and removing
            or altering existing information. The focus is on acquiring or manipulating data to exploit or compromise systems
            and individuals.
            </para>
          <para>
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" /> returns a <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> with a value of <see langword="true" />
            indicating the presence of an indirect attack in the response, and a value of <see langword="false" /> indicating
            the absence of an indirect attack.
            </para>
          <para>
            Note that <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" /> does not support evaluation of multimodal content present in the
            evaluated responses. Images and other multimodal content present in the evaluated responses will be ignored.
            </para>
        </remarks>
      </Docs>
    </Member>
    <Member MemberName="IndirectAttackMetricName">
      <MemberSignature Language="C#" Value="public static string IndirectAttackMetricName { get; }" />
      <MemberSignature Language="ILAsm" Value=".property string IndirectAttackMetricName" />
      <MemberSignature Language="DocId" Value="P:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.IndirectAttackMetricName" />
      <MemberSignature Language="VB.NET" Value="Public Shared ReadOnly Property IndirectAttackMetricName As String" />
      <MemberSignature Language="F#" Value="static member IndirectAttackMetricName : string" Usage="Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator.IndirectAttackMetricName" />
      <MemberSignature Language="C++ CLI" Value="public:&#xA; static property System::String ^ IndirectAttackMetricName { System::String ^ get(); };" />
      <MemberType>Property</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Extensions.AI.Evaluation.Safety</AssemblyName>
        <AssemblyVersion>9.5.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.String</ReturnType>
      </ReturnValue>
      <Docs>
        <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.BooleanMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.IndirectAttackEvaluator" />.
            </summary>
        <value>To be added.</value>
        <remarks>To be added.</remarks>
      </Docs>
    </Member>
  </Members>
</Type>
