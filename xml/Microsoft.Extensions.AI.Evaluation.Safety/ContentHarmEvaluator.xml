<Type Name="ContentHarmEvaluator" FullName="Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator">
  <TypeSignature Language="C#" Value="public class ContentHarmEvaluator : Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />
  <TypeSignature Language="ILAsm" Value=".class public auto ansi beforefieldinit ContentHarmEvaluator extends Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />
  <TypeSignature Language="DocId" Value="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator" />
  <TypeSignature Language="VB.NET" Value="Public Class ContentHarmEvaluator&#xA;Inherits ContentSafetyEvaluator" />
  <TypeSignature Language="F#" Value="type ContentHarmEvaluator = class&#xA;    inherit ContentSafetyEvaluator" />
  <TypeSignature Language="C++ CLI" Value="public ref class ContentHarmEvaluator : Microsoft::Extensions::AI::Evaluation::Safety::ContentSafetyEvaluator" />
  <AssemblyInfo>
    <AssemblyName>Microsoft.Extensions.AI.Evaluation.Safety</AssemblyName>
    <AssemblyVersion>9.4.0.0</AssemblyVersion>
  </AssemblyInfo>
  <Base>
    <BaseTypeName>Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator</BaseTypeName>
  </Base>
  <Interfaces />
  <Docs>
    <param name="contentSafetyServiceConfiguration">
            Specifies the Azure AI project that should be used and credentials that should be used when this
            <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the Azure AI Content Safety service to perform evaluations.
            </param>
    <param name="contentSafetyServiceMetricName">
            The name of the metric that should be used when this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" /> communicates with the
            Azure AI Content Safety service to perform evaluations.
            </param>
    <param name="metricName">
            The name of the <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" /> produced by this <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.
            </param>
    <param name="evaluatorName">The name of the derived <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentSafetyEvaluator" />.</param>
    <param name="metricNames">
             A optional dictionary containing the mapping from the names of the metrics that are used when communicating
             with the Azure AI Foundry Evaluation service, to the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" />s of the
             <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" />s returned by this <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" />.
            
             If omitted, includes mappings for all content harm metrics that are supported by the Azure AI Foundry Evaluation
             service. This includes <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator.HateAndUnfairnessMetricName" />,
             <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator.ViolenceMetricName" />, <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator.SelfHarmMetricName" /> and
             <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator.SexualMetricName" />.
             </param>
    <summary>
             An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Foundry Evaluation service to evaluate responses produced by
             an AI model for the presence of a variety of harmful content such as violence, hate speech, etc.
             </summary>
    <remarks>
      <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator" /> can be used to evaluate responses for all supported content harm metrics in one
             go. You can achieve this by omitting the <paramref name="metricNames" /> parameter.
            
             <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator" /> also serves as a base class for <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator" />,
             <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator" />, <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator" /> and <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator" /> which can be
             used to evaluate responses for one specific content harm metric at a time.
             </remarks>
  </Docs>
  <Members>
    <Member MemberName=".ctor">
      <MemberSignature Language="C#" Value="public ContentHarmEvaluator (System.Collections.Generic.IDictionary&lt;string,string&gt;? metricNames = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig specialname rtspecialname instance void .ctor(class System.Collections.Generic.IDictionary`2&lt;string, string&gt; metricNames) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator.#ctor(System.Collections.Generic.IDictionary{System.String,System.String})" />
      <MemberSignature Language="VB.NET" Value="Public Sub New (Optional metricNames As IDictionary(Of String, String) = Nothing)" />
      <MemberSignature Language="F#" Value="new Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator : System.Collections.Generic.IDictionary&lt;string, string&gt; -&gt; Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator" Usage="new Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator metricNames" />
      <MemberType>Constructor</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Extensions.AI.Evaluation.Safety</AssemblyName>
        <AssemblyVersion>9.4.0.0</AssemblyVersion>
      </AssemblyInfo>
      <Parameters>
        <Parameter Name="metricNames" Type="System.Collections.Generic.IDictionary&lt;System.String,System.String&gt;">
          <Attributes>
            <Attribute FrameworkAlternate="net-10.0-pp;net-8.0-pp;net-9.0-pp">
              <AttributeName Language="C#">[System.Runtime.CompilerServices.Nullable(new System.Byte[] { 2, 1, 1 })]</AttributeName>
              <AttributeName Language="F#">[&lt;System.Runtime.CompilerServices.Nullable(new System.Byte[] { 2, 1, 1 })&gt;]</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
      </Parameters>
      <Docs>
        <param name="metricNames">
             A optional dictionary containing the mapping from the names of the metrics that are used when communicating
             with the Azure AI Foundry Evaluation service, to the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" />s of the
             <see cref="T:Microsoft.Extensions.AI.Evaluation.EvaluationMetric" />s returned by this <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" />.
            
             If omitted, includes mappings for all content harm metrics that are supported by the Azure AI Foundry Evaluation
             service. This includes <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator.HateAndUnfairnessMetricName" />,
             <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator.ViolenceMetricName" />, <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator.SelfHarmMetricName" /> and
             <see cref="P:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator.SexualMetricName" />.
             </param>
        <summary>
             An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that utilizes the Azure AI Foundry Evaluation service to evaluate responses produced by
             an AI model for the presence of a variety of harmful content such as violence, hate speech, etc.
             </summary>
        <remarks>
          <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator" /> can be used to evaluate responses for all supported content harm metrics in one
             go. You can achieve this by omitting the <paramref name="metricNames" /> parameter.
            
             <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator" /> also serves as a base class for <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.HateAndUnfairnessEvaluator" />,
             <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.ViolenceEvaluator" />, <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.SelfHarmEvaluator" /> and <see cref="T:Microsoft.Extensions.AI.Evaluation.Safety.SexualEvaluator" /> which can be
             used to evaluate responses for one specific content harm metric at a time.
             </remarks>
      </Docs>
    </Member>
    <Member MemberName="EvaluateAsync">
      <MemberSignature Language="C#" Value="public override sealed System.Threading.Tasks.ValueTask&lt;Microsoft.Extensions.AI.Evaluation.EvaluationResult&gt; EvaluateAsync (System.Collections.Generic.IEnumerable&lt;Microsoft.Extensions.AI.ChatMessage&gt; messages, Microsoft.Extensions.AI.ChatResponse modelResponse, Microsoft.Extensions.AI.Evaluation.ChatConfiguration? chatConfiguration = default, System.Collections.Generic.IEnumerable&lt;Microsoft.Extensions.AI.Evaluation.EvaluationContext&gt;? additionalContext = default, System.Threading.CancellationToken cancellationToken = default);" />
      <MemberSignature Language="ILAsm" Value=".method public hidebysig virtual instance valuetype System.Threading.Tasks.ValueTask`1&lt;class Microsoft.Extensions.AI.Evaluation.EvaluationResult&gt; EvaluateAsync(class System.Collections.Generic.IEnumerable`1&lt;class Microsoft.Extensions.AI.ChatMessage&gt; messages, class Microsoft.Extensions.AI.ChatResponse modelResponse, class Microsoft.Extensions.AI.Evaluation.ChatConfiguration chatConfiguration, class System.Collections.Generic.IEnumerable`1&lt;class Microsoft.Extensions.AI.Evaluation.EvaluationContext&gt; additionalContext, valuetype System.Threading.CancellationToken cancellationToken) cil managed" />
      <MemberSignature Language="DocId" Value="M:Microsoft.Extensions.AI.Evaluation.Safety.ContentHarmEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)" />
      <MemberSignature Language="VB.NET" Value="Public Overrides NotOverridable Function EvaluateAsync (messages As IEnumerable(Of ChatMessage), modelResponse As ChatResponse, Optional chatConfiguration As ChatConfiguration = Nothing, Optional additionalContext As IEnumerable(Of EvaluationContext) = Nothing, Optional cancellationToken As CancellationToken = Nothing) As ValueTask(Of EvaluationResult)" />
      <MemberSignature Language="F#" Value="override this.EvaluateAsync : seq&lt;Microsoft.Extensions.AI.ChatMessage&gt; * Microsoft.Extensions.AI.ChatResponse * Microsoft.Extensions.AI.Evaluation.ChatConfiguration * seq&lt;Microsoft.Extensions.AI.Evaluation.EvaluationContext&gt; * System.Threading.CancellationToken -&gt; System.Threading.Tasks.ValueTask&lt;Microsoft.Extensions.AI.Evaluation.EvaluationResult&gt;" Usage="contentHarmEvaluator.EvaluateAsync (messages, modelResponse, chatConfiguration, additionalContext, cancellationToken)" />
      <MemberType>Method</MemberType>
      <AssemblyInfo>
        <AssemblyName>Microsoft.Extensions.AI.Evaluation.Safety</AssemblyName>
        <AssemblyVersion>9.4.0.0</AssemblyVersion>
      </AssemblyInfo>
      <ReturnValue>
        <ReturnType>System.Threading.Tasks.ValueTask&lt;Microsoft.Extensions.AI.Evaluation.EvaluationResult&gt;</ReturnType>
        <Attributes>
          <Attribute FrameworkAlternate="net-10.0-pp">
            <AttributeName Language="C#">[System.Runtime.CompilerServices.Nullable(new System.Byte[] { 0, 1 })]</AttributeName>
            <AttributeName Language="F#">[&lt;System.Runtime.CompilerServices.Nullable(new System.Byte[] { 0, 1 })&gt;]</AttributeName>
          </Attribute>
        </Attributes>
      </ReturnValue>
      <Parameters>
        <Parameter Name="messages" Type="System.Collections.Generic.IEnumerable&lt;Microsoft.Extensions.AI.ChatMessage&gt;" />
        <Parameter Name="modelResponse" Type="Microsoft.Extensions.AI.ChatResponse" />
        <Parameter Name="chatConfiguration" Type="Microsoft.Extensions.AI.Evaluation.ChatConfiguration">
          <Attributes>
            <Attribute FrameworkAlternate="net-10.0-pp;net-8.0-pp;net-9.0-pp">
              <AttributeName Language="C#">[System.Runtime.CompilerServices.Nullable(2)]</AttributeName>
              <AttributeName Language="F#">[&lt;System.Runtime.CompilerServices.Nullable(2)&gt;]</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
        <Parameter Name="additionalContext" Type="System.Collections.Generic.IEnumerable&lt;Microsoft.Extensions.AI.Evaluation.EvaluationContext&gt;">
          <Attributes>
            <Attribute FrameworkAlternate="net-10.0-pp;net-8.0-pp;net-9.0-pp">
              <AttributeName Language="C#">[System.Runtime.CompilerServices.Nullable(new System.Byte[] { 2, 1 })]</AttributeName>
              <AttributeName Language="F#">[&lt;System.Runtime.CompilerServices.Nullable(new System.Byte[] { 2, 1 })&gt;]</AttributeName>
            </Attribute>
          </Attributes>
        </Parameter>
        <Parameter Name="cancellationToken" Type="System.Threading.CancellationToken" />
      </Parameters>
      <Docs>
        <param name="messages">To be added.</param>
        <param name="modelResponse">To be added.</param>
        <param name="chatConfiguration">To be added.</param>
        <param name="additionalContext">To be added.</param>
        <param name="cancellationToken">To be added.</param>
        <summary>To be added.</summary>
        <returns>To be added.</returns>
        <remarks>To be added.</remarks>
        <inheritdoc />
      </Docs>
    </Member>
  </Members>
</Type>
